import psycopg2
import pandas as pd
import joblib
import boto3
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest

# âœ… Cáº¥u hÃ¬nh AWS S3
AWS_ACCESS_KEY = "AKIA2YICARIK4JD7HOZX"
AWS_SECRET_KEY = "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"
AWS_BUCKET_NAME = "my-hose-data"
S3_FOLDER_CSV = "data_model/"    # ğŸ“ NÆ¡i lÆ°u file CSV
S3_FOLDER_MODELS = "models/"     # ğŸ“ NÆ¡i lÆ°u mÃ´ hÃ¬nh

# Khá»Ÿi táº¡o S3 client
s3 = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY,
    aws_secret_access_key=AWS_SECRET_KEY
)

# âœ… ThÃ´ng tin káº¿t ná»‘i PostgreSQL
DATABASE_URL = "postgresql://data_owner:npg_lXG4nWhfUk0P@ep-cold-tooth-a1p19dl8-pooler.ap-southeast-1.aws.neon.tech/data?sslmode=require"
TABLE_NAME = "bao_cao_kqkd"  

# âœ… Káº¿t ná»‘i vÃ  láº¥y dá»¯ liá»‡u tá»« PostgreSQL
def get_data_from_postgres():
    conn = psycopg2.connect(DATABASE_URL)
    query = f"SELECT * FROM {TABLE_NAME}"
    df = pd.read_sql(query, conn)
    conn.close()
    return df

df = get_data_from_postgres()

# âœ… Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
features = ['doanhthuthuan', 'loinhuangop', 'loinhuanthuan', 'loinhuantruocthue', 'loinhuansauthue', 'laitrencophieu']
df_features = df[features].dropna()

# âœ… Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# âœ… Táº¡o mÃ´ hÃ¬nh Isolation Forest
model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)
model.fit(df_scaled)

# âœ… LÆ°u mÃ´ hÃ¬nh táº¡m thá»i
MODEL_FILE = "isolation_forest_model.pkl"
joblib.dump(model, MODEL_FILE)
print(f"âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u táº¡i {MODEL_FILE}")

# âœ… Äáº©y mÃ´ hÃ¬nh lÃªn AWS S3 (ğŸ“ `models/`)
try:
    s3.upload_file(MODEL_FILE, AWS_BUCKET_NAME, S3_FOLDER_MODELS + MODEL_FILE)
    print(f"ğŸš€ ÄÃ£ upload {MODEL_FILE} lÃªn s3://{AWS_BUCKET_NAME}/{S3_FOLDER_MODELS}{MODEL_FILE}")
except Exception as e:
    print(f"âŒ Lá»—i khi upload {MODEL_FILE}: {str(e)}")

# âœ… Dá»± Ä‘oÃ¡n cÃ¡c báº¥t thÆ°á»ng
predictions = model.predict(df_scaled)
df['is_anomaly'] = predictions

# âœ… Lá»c cÃ¡c doanh nghiá»‡p cÃ³ bÃ¡o cÃ¡o tÃ i chÃ­nh báº¥t thÆ°á»ng
anomalies = df[df['is_anomaly'] == -1]
ANOMALY_FILE = "anomalous_companies.csv"
anomalies.to_csv(ANOMALY_FILE, index=False)

print("\nğŸš¨ CÃ¡c doanh nghiá»‡p cÃ³ bÃ¡o cÃ¡o tÃ i chÃ­nh báº¥t thÆ°á»ng:")
print(anomalies[['mack', 'doanhthuthuan', 'loinhuanthuan', 'loinhuansauthue', 'is_anomaly']])

# âœ… Äáº©y file anomalies lÃªn AWS S3 (ğŸ“ `data_model/`)
try:
    s3.upload_file(ANOMALY_FILE, AWS_BUCKET_NAME, S3_FOLDER_CSV + ANOMALY_FILE)
    print(f"ğŸš€ ÄÃ£ upload {ANOMALY_FILE} lÃªn s3://{AWS_BUCKET_NAME}/{S3_FOLDER_CSV}{ANOMALY_FILE}")
except Exception as e:
    print(f"âŒ Lá»—i khi upload {ANOMALY_FILE}: {str(e)}")

# âœ… Kiá»ƒm tra láº¡i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u tá»« S3
model_loaded = joblib.load(MODEL_FILE)
predictions_loaded = model_loaded.predict(df_scaled)
print("\nâœ… Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh Ä‘Ã£ táº£i láº¡i:")
print(predictions_loaded)
